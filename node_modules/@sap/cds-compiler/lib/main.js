// Main entry point for the Research Vanilla CDS Compiler
//
// File for external usage = which is read in other modules with
//   require('cdsv');

// Proposed intra-module lib dependencies:
//  - lib/base/<file>.js: can be required by all others, requires no other
//    of this project
//  - lib/<dir>/<file>.js: can be required by other files lib/<dir>/,
//    can require other files lib/<dir>/ and lib/base/<file>.js
//  - lib/main.js (this file): can be required by none in lib/ (only in
//    bin/ and test/), can require any other

'use strict';

const backends = require('./backends');
const { odata, cdl, sql, hdi, hdbcds, edm, edmx } = require('./api/main');
const { emptyWeakLocation } = require('./base/location');

// The compiler version (taken from package.json)
function version() {
  return require('../package.json').version;
}

const { CompilationError, messageString, messageStringMultiline, messageContext, handleMessages, hasErrors, getMessageFunction }
    = require('./base/messages');
const { promiseAllDoNotRejectImmediately } = require('./base/node-helpers');

const assertConsistency = require('./compiler/assert-consistency');
const parseLanguage = require('./language/antlrParser');
const moduleLayers = require('./compiler/moduleLayers');
const { define } = require('./compiler/definer');
const resolve = require('./compiler/resolver');
const propagator = require('./compiler/propagator');
const semanticChecks = require('./checks/semanticChecks');
const compactJson = require('./json/compactor').compact;
const compactSortedJson = require('./json/compactor').compactSorted;
const { compactModel, compactQuery, compactExpr } = require('./json/to-csn')
const fs = require('fs');
const emdx2csn = require('./edm/annotations/edmx2csn'); // translate edmx annotations into csn

const path = require('path');
const moduleResolve = require('resolve');

const extensions = ['.cds', '.csn', '.csn.json', '.json'];

function packageFilter( pkg ) {
  return { main: pkg.cds && pkg.cds.main || pkg.main };
}

/**
 * Parse the given source with the correct parser based on the file name's
 * extension. For example use edm2csn for `.xml` files and the CDL parser
 * for `.cds` files.
 *
 * @param {string} source Source code of the file.
 * @param {string} filename Filename including its extension, e.g. "file.cds"
 * @param {object} options Compile options
 */
function parse( source, filename, options = {} ) {
  const ext = path.extname( filename ).toLowerCase();
  if (ext === '.xml') {
    return emdx2csn( source, filename, options );
  }
  else if (['.json', '.csn'].includes(ext)) {
    return require('./json/from-csn').parse( source, filename, options );
  } else if (options.fallbackParser || ['.cds', '.hdbcds', '.hdbdd'].includes(ext))
    return parseLanguage( source, filename, options );
  else {
    const model = {};
    const message = getMessageFunction( model, options );
    message( 'file-unknown-ext',
             emptyWeakLocation(filename), null,
             { file: ext && ext.slice(1), '#': !ext && 'none' },
             'Error', {
               std:  'Unknown file extension $(FILE)',
               none: 'No file extension'
             } );
    return model;
  }
}

// Collect all sources for the given files in the given base directory.
// This means that all dependency sources (e.g. `using` statements) are
// loaded and stored.
// This function returns a Promise (i.e. calls compile() which returns
// a promise). The fulfullment value is an object with all sources and
// their dependencies.
function collectSources( filenames, basedir ) {
  return compile( filenames, basedir, { collectSources: true } );
}

// Main function: Compile the sources from the files given by the array of
// `filenames`.  As usual with the `fs` library, relative file names are
// relative to the working directory `process.cwd()`.  With argument `dir`, the
// file names are relative to `process.cwd()+dir`.  Options can have the
// following properties:
//  - Truthy `parseOnly`: stop compilation after parsing.
//  - Truthy `lintMode`: do not do checks and propagation
//  - many others - TODO

// This function returns a Promise.  See ../bin/cdsv.js for an example usage.
// See function `compileSync` or `compileSources` for alternative compile
// functions.
//
// The promise is fulfilled if all files could be read and processed without
// errors.  The fulfillment value is an augmented CSN (see
// ./compiler/definer.js).
//
// If there are errors, the promise is rejected.  If there was an invocation
// error (repeated filenames or if the file could not be read), the rejection
// value is an InvocationError.  Otherwise, the rejection value is a
// CompilationError containing a vector of individual errors.
//
// `fileCache` is a dictionary of absolute file names to the file content
//  - false: the file does not exist
//  - true: file exists (fstat), no further knowledge yet - i.e. value will change!
//  - 'string' or instanceof Buffer: the file content
//  - { realname: fs.realpath(filename) }: if filename is not canonicalized
//
function compile( filenames, dir='', options = {}, fileCache = Object.create(null) ) {
  // A non-proper dictionary (i.e. with prototype) is safe if the keys are
  // absolute file names - they start with `/` or `\` or similar
  // if (Object.getPrototypeOf( fileCache ))
  //   fileCache = Object.assign( Object.create(null), fileCache );
  dir = path.resolve(dir);
  const a = processFilenames( filenames, dir );
  a.fileContentDict = Object.create(null);

  const model = { sources: a.sources, options };
  const message = getMessageFunction( model );
  const parseOptions = optionsWithMessages( options, model );
  let all = promiseAllDoNotRejectImmediately( a.files.map(readAndParse) );

  all = all
    .then( testInvocation, function (reason) {
      // do not reject with PromiseAllError, use InvocationError:
      const errs = reason.valuesOrErrors.filter (e => e instanceof Error);
      // internal error if no file IO error (has property `path`)
      return Promise.reject( errs.find( e => !e.path ) ||
                             new InvocationError([...a.repeated, ...errs]) )
    });
  if (!options.parseOnly && !options.parseCdl)
    all = all.then( readDependencies );
  return all.then( function() {
    moduleLayers.setLayers( a.sources );
    if (options.collectSources)
      return collect();
    return compileDo( model );
  });

  function collect() {
    handleMessages( model );
    let dependencies = Object.create(null);
    for (let name in a.sources) {
      let deps = a.sources[name].dependencies;
      if (deps && deps.length) {
        let mod = Object.create(null);
        deps.forEach( d => mod[ d.val ] = d.realname );
        dependencies[name] = mod;
      }
    }
    return { sources: a.fileContentDict, dependencies, files: a.files };
  }

  // Read file `filename` and parse its content, return messages
  function readAndParse( filename ) {
    if ( filename === false )   // module which has not been found
      return [];
    let rel = a.sources[filename] || path.relative( dir, filename );
    if (typeof rel === 'object') // already parsed
      return [];                 // no further dependency processing
    // no parallel readAndParse with same resolved filename should read the file,
    // also ensure deterministic sequence in a.sources:
    a.sources[filename] = { filename: rel };

    return new Promise( function (fulfill, reject) {
      readFile( filename, 'utf8', function (err, source) {
        if (err)
          reject(err);
        else {
          try {
            a.fileContentDict[filename] = source;
            let ast = parse( source, rel, parseOptions );
            a.sources[filename] = ast;
            ast.filename = rel;
            ast.dirname = path.dirname( filename );
            assertConsistency( ast, parseOptions );
            fulfill( ast );
          } catch(e){
            reject(e);
          }
        }
      });
    });
  }

  function readFile( filename, enc, cb ) {
    if (typeof enc === 'function') // moduleResolve uses old-style API
      cb = enc, enc = null;
    let body = fileCache[ filename ];
    if (body && typeof body === 'object' && body.realname) {
      filename = body.realname; // use fs.realpath name
      body = fileCache[ filename ];
    }
    if (body !== undefined && body !== true) { // true: we just know it is there
      if (body === false) {
        body = new Error( `ENOENT: no such file or directory, open '${filename}'`);
        body.code = 'ENOENT', body.errno = -2, body.syscall = 'open';
        body.path = filename;
      }
      if (body instanceof Error) {
        traceFS( 'READFILE:cache-error:', filename, body.message );
        cb( body )   // no need for process.nextTick( cb, body ) with moduleResolve
      }
      else {
        traceFS( 'READFILE:cache:', filename, body );
        cb( null, body );
      }
    }
    else {
      traceFS( 'READFILE:start:', filename );
      // TODO: set cache directly to some "delay" - store error differently?
      // e.g. an error of callback functions!
      fs.readFile( filename, enc, function( err, data ) {
        fileCache[ filename ] = err || data;
        traceFS( 'READFILE:data:', filename, err || data );
        cb( err, data );
      });
    }
  }

  function isFile( filename, cb ) {
    let body = fileCache[ filename ];
    if (body !== undefined) {
      traceFS( 'ISFILE:cache:', filename, body );
      if (body instanceof Error)
        cb( body )   // no need for process.nextTick( cb, body ) with moduleResolve
      else
        cb( null, !!body );
    }
    else {
      traceFS( 'ISFILE:start:', filename, body );
      // in the future (if we do module resolve ourself with just readFile),
      // we avoid parallel readFile by storing having an array of `cb`s in
      // fileCache[ filename ] before starting fs.readFile().
      fs.stat( filename, function( err, stat ) {
        if (err)
          body = (err.code === 'ENOENT' || err.code === 'ENOTDIR') ? false : err;
        else
          body = !!(stat.isFile() || stat.isFIFO());
        if (fileCache[ filename ] === undefined) // parallel readFile() has been processed
          fileCache[ filename ] = body;
        traceFS( 'ISFILE:data:', filename, body );
        if (body instanceof Error)
          cb( err );
        else
          cb( null, body );
      });
    }
  }

  function traceFS( intro, filename, data ) {
    if (options.traceFs)
      // eslint-disable-next-line no-console
      console.log( intro, filename,
                   (typeof data === 'string' || data instanceof Buffer)
                   ? typeof data
                   : (data === undefined) ? '?' : '' + data );
  }

  // Combine the parse results (if there are not file IO errors)
  function testInvocation( values ) {
    if (a.repeated.length)
      // repeated file names in invocation => just report these
      return Promise.reject( new InvocationError(a.repeated) );
    return values;
  }

  function readDependencies( astArray ) {
    let promises = [];
    for (let ast of astArray) {
      // console.log( 'READ-DEP:',ast.filename, ast.dependencies && ast.dependencies.length )
      if (!ast.dependencies || !ast.dependencies.length)
        continue;
      let dependencies = Object.create( null );
      for (let d of ast.dependencies) {
        let module = d.val;
        let dep = dependencies[module];
        if (dep)
          dep.usingFroms.push( d );
        else
          dependencies[module] = { module, basedir: ast.dirname, usingFroms: [d] };
      }
      // create promises after all usingFroms have been collected, as the
      // Promise executor is called immediately with `new`:
      for (let module in dependencies)
        promises.push( resolveModule( dependencies[module] ) );
    }
    if (!promises.length)
      return [];
    // read files (important part: adding filename to a.sources) after having
    // resolved the module names to ensure deterministic sequence in a.sources
    return Promise.all( promises )
      .then( fileNames => Promise.all( fileNames.map( readAndParse ) ) )
      .then( readDependencies );
  }

  function resolveModule( dep ) {
    // let opts = { extensions, packageFilter, basedir: dep.basedir, preserveSymlinks: false };
    // `preserveSymlinks` option does not really work -> provide workaround anyway...
    // Hm, the resolve package also does not follow the node recommendation:
    // "Using fs.stat() to check for the existence of a file before calling
    // fs.open(), fs.readFile() or fs.writeFile() is not recommended"
    let opts = { extensions, packageFilter, basedir: dep.basedir, isFile, readFile };
    return new Promise( function (fulfill, reject) {
      // If the global 'cds.home' is set, read modules starting with '@sap/cds/' from there.
      // TODO: re-think:
      // * what is wrong for a JAVA installation to set a link...
      // * preferred to a local installation? Not the node-way...
      // * a global?  The Umbrella could pass it as an option...
      let path = (global['cds'] && global['cds'].home && dep.module.startsWith( '@sap/cds/' ))
          ? global['cds'].home + dep.module.slice(8) // path.resolve() does not work - huh?
          : dep.module;
      moduleResolve( path, opts, function (err, res) {
        // console.log('RESOLVE', dep, res, err)
        if (err)
          reject(err);
        else {
          let body = fileCache[ res ];
          if (body === undefined || body === true) { // use fs if no or just temp entry
            dep.absname = res;
            fs.realpath( res, cb );
          }
          else if (body && typeof body === 'object' && body.realname) {
            //dep.absname = body.realname;
            cb( null, body.realname ); // use fs.realpath name
          }
          else {
            //dep.absname = res;
            cb( null, res );
          }
        }
      });

      function cb( err, res ) {
        if (err)
          reject(err);
        else {
          if (dep.absname)
            fileCache[ dep.absname ] = (dep.absname === res) || { realname: res };
          dep.resolved = res;   // store in dep that module resolve was successful
          for (let from of dep.usingFroms)
            from.realname = res;
          fulfill(res);
        }
      }
    })
      .catch( function() {      // (err)  TODO: check for expected exceptions
        if (dep.resolved) {
          let resolved = path.relative( dep.basedir, dep.resolved );
          if (options.testMode)
            resolved = resolved.replace( /\\/g, '/' );
          for (let from of dep.usingFroms)
            message( 'file-not-readable', from.location, null, { file: resolved },
                     'Error', 'Cannot read file $(FILE)' );
        }
        else if (/^\.\.?\//.test( dep.module ) ) {
          for (let from of dep.usingFroms)
            message( 'file-unknown-local', from.location, null, { file: dep.module },
                     'Error', 'Cannot find local module $(FILE)' );
        }
        else {
          let internal = /[\\/]/.test( dep.module ) && 'internal';
          for (let from of dep.usingFroms)
            message( 'file-unknown-package', from.location, null,
                     { file: dep.module, '#': internal },
                     'Error', {
                       std:      'Cannot find package $(FILE)',
                       internal: 'Cannot find package module $(FILE)'
                     } );
        }
        return false;
      });
  }
}

/**
 * Synchronous version of function `compile` with limited functionality:
 *  - option `--follow-deps` is not supported,
 *  - an invocation error ends the compilation immediately.
 *
 * @param {string[]} filenames Files to compile.
 * @param {string} [dir=""] Base directory. All files are resolved relatively
 *                          to this directory
 * @param {object} [options={}] Compilation options.
 * @returns {XSN.Model} Augmented CSN
 */
function compileSync( filenames, dir = '', options = {} ) {
  dir = path.resolve(dir);
  const processedFiles = processFilenames(filenames, dir);
  const sources = Object.create(null);
  if (processedFiles.repeated.length)
    throw new InvocationError(processedFiles.repeated);

  try {
    for (const filename of processedFiles.files) {
      const source = fs.readFileSync( filename, 'utf8' );
      sources[ processedFiles.sources[filename] ] = source;
    }
  }
  catch (e) {
    throw new InvocationError( [e] );
  }
  return compileSources( sources, options );
}

/**
 * Promise-less main functions: compile the given sources.
 *
 * Argument `sourcesDict` is a dictionary (it could actually be a ordinary object)
 * mapping filenames to either source texts (string) or XSN objects (AST-like
 * augmented CSNs).  It could also be a simple string, which is then considered
 * to be the source text of a file named `<stdin>.cds`.  Argument `sourcesDict`
 * could also be the output of collectSources(), see above.
 *
 * See function `compile` for the meaning of the argument `options`.  If there
 * are parse or other compilation errors, throw an exception CompilationError
 * containing a vector of individual errors.
 *
 * @param {string|object} sourcesDict Files to compile.
 * @param {object} [options={}] Compilation options.
 * @returns {XSN.Model} Augmented CSN
 */
function compileSources( sourcesDict, options = {} ) {

  const content = sourcesDict.sources ? sourcesDict.sources :
    (typeof sourcesDict === 'string') ? { '<stdin>.cds': sourcesDict } : sourcesDict;

  const sources = Object.create(null);
  const model = { sources, options };
  getMessageFunction( model );  // make sure that we have a "central" messages array
  const parseOptions = optionsWithMessages( options, model );

  for (const filename in content) {
    const source = content[filename];
    if (typeof source === 'string') {
      const ast = parse( source, filename, parseOptions );
      sources[filename] = ast;
      ast.filename = filename;
      assertConsistency( ast, parseOptions );
    }
    else {                      // source is a XSN object (CSN/CDL parser output)
      sources[filename] = source;
    }
  }

  // add dependencies to AST
  for (const filename in sourcesDict.dependencies) {
    const dependency = sourcesDict.dependencies[ filename ];
    for (const val in dependency) {
      const dep = { literal: 'string', val, realname: dependency[val] /*, location: ???*/};
      const arr = sources[filename].dependencies;
      if (arr)
        arr.push( dep );
      else
        sources[filename].dependencies = [ dep ];
    }
  }
  moduleLayers.setLayers( sources );

  return compileDo( model );
}

// Make sure to use a "central" messages array during parsing:
function optionsWithMessages( options, model ) {
  return (options.messages)
    ? options
    // : node 8.3 / elint-5+: { messages: model.messages, ...options };
    : Object.assign( { messages: model.messages }, options );
}

/**
 * On the given model (AST like CSN) run the definer, resolver as well as semantic checks.
 * Creates an augmented CSN (XSN) and returns it.
 *
 * @param {object} model AST like CSN generated e.g. by `parseLanguage()`
 * @returns {XSN.Model} Augmented CSN (XSN)
 */
function compileDo( model ) {
  const options = model.options;
  if (!options.testMode) {
    model.meta = {}; // provide initial central meta object
  }
  if (options.parseOnly)
    return handleMessages( model );

  define( model );

  // do not run the resolver in parse-cdl mode or we get duplicate annotations, etc.
  if (options.parseCdl)
    return handleMessages( model );

  resolve( model );
  assertConsistency( model );
  handleMessages( model );      // stop compilation with errors
  if (options.lintMode)
    return model;

  semanticChecks(model);
  handleMessages( model );
  return propagator.propagate( model );
}

// Process an array of `filenames`.  Returns an object with properties:
//  - `sources`: dictionary which has a filename as key (value is irrelevant)
//  - `files`: the argument array without repeating the same name
//  - `repeated`: array of filenames which have been repeatedly listed
//    (listed only once here even if listed thrice)
//
// Note: there is nothing file-specific about the filenames, the filenames are
// not normalized - any strings work
function processFilenames( filenames, dir ) {
  const sources = Object.create(null); // not {} = no [[Prototype]]
  const files = [];
  const repeated = [];

  for (const originalName of filenames) {
    let name = path.resolve(dir, originalName);

    try {
      // Resolve possible symbolic link; if the file does not exist
      // we just continue using the original name because readFile()
      // already handles non-existent files.
      name = fs.realpathSync(name);
    }
    catch (e) {
      // Ignore the not-found (ENOENT) error
    }

    if (sources[name] == null) {
      sources[name] = path.relative( dir, name );
      files.push(name);
    }
    else if (typeof sources[name] === 'string') { // not specified more than twice
      const msg = 'Repeated argument: file \'' + sources[name] + '\'';
      repeated.push( new ArgumentError( name, msg ) );
    }
  }
  return { sources, files, repeated };
}

// Class for command invocation errors.  Additional members:
//  `errors`: vector of errors (file IO or ArgumentError)
class InvocationError extends Error {
  constructor(errs,...args) {
    super(...args);
    this.errors = errs;
    this.hasBeenReported = false;
  }
}

// Class for argument errors.  Additional members:
//  `argument`: the command argument (repeated file names)
class ArgumentError extends Error {
  constructor(arg,...args) {
    super(...args);
    this.argument = arg;
  }
}

function parseToCqn( cdl, filename = '<query>.cds', options = {} ) {
  let xsn = parseLanguage( cdl, filename, Object.assign( {parseOnly:true}, options ), 'query' );
  handleMessages( xsn );
  return compactQuery( xsn );
}

function parseToExpr( cdl, filename = '<expr>.cds', options = {} ) {
  let xsn = parseLanguage( cdl, filename, Object.assign( {parseOnly:true}, options ), 'expr' );
  handleMessages( xsn );
  return compactExpr( xsn );
}

// FIXME: The implementation of those functions that delegate to 'backends' should probably move here
module.exports = {
  // Compiler
  version,
  parse,
  collectSources,
  compile,                      // main function
  compileSync,                  // main function
  compileSources,               // main function
  compactJson,                  // should rather use toCsn
  compactSortedJson,            // should rather use toCsn
  compactModel,
  CompilationError,
  messageString,
  messageStringMultiline,
  messageContext,
  InvocationError,
  hasErrors,

  // Backends
  toHana : backends.toHana,
  toOdata : backends.toOdata,
  // TODO: Expose when transformers are switched to CSN
  // toOdataWithCsn: backends.toOdataWithCsn,
  preparedCsnToEdmx : backends.preparedCsnToEdmx,
  preparedCsnToEdm : backends.preparedCsnToEdm,
  toCdl : backends.toCdl,
  toSwagger : backends.toSwagger,
  toSql : backends.toSql,
  toCsn : backends.toCsn,
  toRename : backends.toRename, // Tentative, subject to change

  // additional API:
  parseToCqn,
  parseToExpr,
  for: { odata },
  to: { cdl, sql, hdi, hdbcds, edm, edmx }
};
